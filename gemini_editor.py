import io
import torch
import numpy as np
from PIL import Image
from google import genai

MODEL_NAME = "gemini-2.5-flash-image-preview"

# --- å·¥å…·å‡½æ•° ---
def tensor_to_pil(tensor):
    if tensor is None:
        return None
    arr = (tensor[0].cpu().numpy() * 255).astype(np.uint8)
    return Image.fromarray(arr)

def pil_to_tensor(pil_image):
    return torch.from_numpy(np.array(pil_image).astype(np.float32) / 255.0).unsqueeze(0)

# --- èŠ‚ç‚¹ç±» ---
class GeminiFlash25Node:
    """
    ComfyUI èŠ‚ç‚¹: Gemini Flash 2.5 (Text / Image-to-Image)
    ä½¿ç”¨ Google Gemini Flash 2.5 æ¨¡å‹ç”Ÿæˆæˆ–ç¼–è¾‘å›¾åƒã€‚
    """

    @classmethod
    def INPUT_TYPES(s):
        img_inputs = {f"image_{i:02d}": ("IMAGE",) for i in range(1, 11)}
        required = {
            "api_key": ("STRING", {"multiline": False, "default": ""}),
            "prompt": ("STRING", {"multiline": True, "default": "A futuristic cityscape at sunset"}),
        }
        return {"required": required, "optional": img_inputs}

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("generated_image", "text_response")
    FUNCTION = "generate_image"
    CATEGORY = "Gemini"

    def generate_image(self, api_key, prompt, **kwargs):
        # --- API Key ---
        key = api_key.strip()
        if not key:
            raise ValueError("âŒ Gemini API Key is required. è¯·åœ¨èŠ‚ç‚¹å‚æ•°ä¸­å¡«å†™ API Keyã€‚")

        client = genai.Client(api_key=key)

        # --- æ”¶é›†è¾“å…¥ ---
        parts = []
        for i in range(1, 11):
            image_tensor = kwargs.get(f"image_{i:02d}")
            if image_tensor is not None:  # âœ… æ˜¾å¼åˆ¤æ–­ None
                parts.append(tensor_to_pil(image_tensor))
        if prompt:
            parts.append(prompt)

        if not parts:
            raise ValueError("âŒ å¿…é¡»è‡³å°‘æä¾›ä¸€ä¸ª prompt æˆ– ä¸€å¼ è¾“å…¥å›¾åƒã€‚")

        # --- è°ƒç”¨ Gemini Flash 2.5 ---
        try:
            print(f"[GeminiNode] è°ƒç”¨æ¨¡å‹ {MODEL_NAME} ...")
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=parts,
            )

            image_tensor, text_res = None, ""
            for part in response.candidates[0].content.parts:
                if getattr(part, "inline_data", None):
                    pil_img = Image.open(io.BytesIO(part.inline_data.data))
                    image_tensor = pil_to_tensor(pil_img)
                if getattr(part, "text", None):
                    text_res += part.text + "\n"

            if image_tensor is None:
                raise RuntimeError(f"âš ï¸ Gemini Flash æ²¡è¿”å›å›¾åƒã€‚æ–‡æœ¬ç»“æœ: {text_res.strip()}")

            return image_tensor, text_res.strip()

        except Exception as e:
            raise RuntimeError(f"ğŸ”¥ Gemini Flash API è°ƒç”¨é”™è¯¯: {e}")

# --- èŠ‚ç‚¹æ³¨å†Œ ---
NODE_CLASS_MAPPINGS = {"GeminiFlash25Node": GeminiFlash25Node}
NODE_DISPLAY_NAME_MAPPINGS = {"GeminiFlash25Node": "Gemini Flash 2.5 Gen/Edit"}
